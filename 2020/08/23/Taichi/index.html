<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"artemisaturn.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="1、The Taichi Programming LanguageDataData typesTaichi is strongly typed. Supported basics types include:  Signed integers:  ti.i8&#x2F;i16&#x2F;i32&#x2F;i64 Unsigned integers:  ti.u8&#x2F;u16&#x2F;u32&#x2F;u64 Float-point numbers:">
<meta property="og:type" content="article">
<meta property="og:title" content="Taichi">
<meta property="og:url" content="https://artemisaturn.github.io/2020/08/23/Taichi/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="1、The Taichi Programming LanguageDataData typesTaichi is strongly typed. Supported basics types include:  Signed integers:  ti.i8&#x2F;i16&#x2F;i32&#x2F;i64 Unsigned integers:  ti.u8&#x2F;u16&#x2F;u32&#x2F;u64 Float-point numbers:">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://hexo-1257922593.cos.ap-beijing.myqcloud.com/taichi/mass_spring.png">
<meta property="article:published_time" content="2020-08-23T15:09:03.000Z">
<meta property="article:modified_time" content="2020-09-05T00:46:35.665Z">
<meta property="article:author" content="Daphne Wang">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://hexo-1257922593.cos.ap-beijing.myqcloud.com/taichi/mass_spring.png">

<link rel="canonical" href="https://artemisaturn.github.io/2020/08/23/Taichi/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Taichi | Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://artemisaturn.github.io/2020/08/23/Taichi/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Daphne Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Taichi
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-23 23:09:03" itemprop="dateCreated datePublished" datetime="2020-08-23T23:09:03+08:00">2020-08-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-09-05 08:46:35" itemprop="dateModified" datetime="2020-09-05T08:46:35+08:00">2020-09-05</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="1、The-Taichi-Programming-Language"><a href="#1、The-Taichi-Programming-Language" class="headerlink" title="1、The Taichi Programming Language"></a>1、The Taichi Programming Language</h1><h2 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h2><h3 id="Data-types"><a href="#Data-types" class="headerlink" title="Data types"></a>Data types</h3><p>Taichi is strongly typed. Supported basics types include:</p>
<ul>
<li>Signed integers:  ti.i8/i16/i32/i64</li>
<li>Unsigned integers:  ti.u8/u16/u32/u64</li>
<li>Float-point numbers:  ti.f32/f64</li>
</ul>
<h3 id="Tensors"><a href="#Tensors" class="headerlink" title="Tensors"></a>Tensors</h3><p>Taichi is a data-oriented programming language where tensors are first-class citizens.</p>
<ul>
<li>Tensors are essentially multi-dimensional arrays.（在Taichi种，tensor和matrix是两个完全不同的概念）</li>
<li>An element of a tensor can be either a scalar(var), a vector(ti.Vector), or a matrix(ti.Matrix)</li>
<li>Tensor elements are always accessed via the a[i, j, k] syntax. (No pointers! 编译器不易优化)</li>
<li>Access out-of-bound is undefined behavior.</li>
<li>Tensors can be spatially  sparse.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> taichi <span class="keyword">as</span> ti</span><br><span class="line">ti.init()</span><br><span class="line">a = ti.var(dt=ti.f32, shape=(<span class="number">42</span>, <span class="number">63</span>)) <span class="comment"># A tensor of 42x63 scalars</span></span><br><span class="line">b = ti.Vector(<span class="number">3</span>, dt=ti.f32, shape=<span class="number">4</span>) <span class="comment"># A tensor of 4x3D vectors</span></span><br><span class="line">C = ti.Matrix(<span class="number">2</span>, <span class="number">2</span>, dt=ti.f32, shape=(<span class="number">3</span>, <span class="number">5</span>)) <span class="comment"># A tensor pf 3x5 2x2 matrices</span></span><br><span class="line">loss = ti.var(dt=ti.f32, shape=()) <span class="comment"># A (0-D) tensor of a single scalar</span></span><br><span class="line"></span><br><span class="line">a[<span class="number">3</span>, <span class="number">4</span>] = <span class="number">1</span></span><br><span class="line">print(<span class="string">'a[3, 4] = '</span>, a[<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"><span class="comment"># "a[3, 4] = 1.000000"</span></span><br><span class="line"></span><br><span class="line">b[<span class="number">2</span>] = [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line">print(<span class="string">'b[0] ='</span>, b[<span class="number">0</span>][<span class="number">0</span>], b[<span class="number">0</span>][<span class="number">1</span>], b[<span class="number">0</span>][<span class="number">2</span>])</span><br><span class="line"><span class="comment"># print(b[0]) is not yet supported</span></span><br><span class="line"></span><br><span class="line">loss[<span class="literal">None</span>] = <span class="number">3</span> <span class="comment"># 没有下标</span></span><br><span class="line">print(loss[<span class="literal">None</span>]) <span class="comment"># 3</span></span><br></pre></td></tr></table></figure>

<p>a（标量张量）：有42x63个元素，每个元素是一个标量</p>
<p>b（向量张量）：tensor长度为4，向量有3个元素，4个3D vectors组成的张量</p>
<p>c（矩阵张量）：3x5的tensor，里面每个元素是一个2x2的矩阵</p>
<p>loss：0-D的张量，只有一个标量元素</p>
<h2 id="computation"><a href="#computation" class="headerlink" title="computation"></a>computation</h2><h3 id="Kernels"><a href="#Kernels" class="headerlink" title="Kernels"></a>Kernels</h3><p>Kernels——用来计算的函数。</p>
<ul>
<li>The language used in Taichi kernels and functions is similar to Python.（区别：该语言会被即时编译，Taichi自带一个编译器，把kernel里的语言编译成高性能kernel，能够运行的更快。）</li>
<li>The Taichi kernel lanuage is compiled, statically-typed, lexically-scoped, parallel and differentiable.</li>
<li>Kernels must be decorated with @ti.kernel.</li>
<li>Kernel arguments and return values must be type-hinted.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello</span><span class="params">(i: ti.i32)</span>:</span></span><br><span class="line">    a = <span class="number">40</span></span><br><span class="line">    print(<span class="string">'Hello world!'</span>, a + i)</span><br><span class="line">    </span><br><span class="line">hello(<span class="number">2</span>) <span class="comment"># Hello world! 42</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc</span><span class="params">()</span> -&gt; ti.i32:</span></span><br><span class="line">    s = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        s += i</span><br><span class="line">    <span class="keyword">return</span> s  <span class="comment"># 45</span></span><br></pre></td></tr></table></figure>

<h3 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h3><p>Taichi Functions 可以被 Taichi Kernels 调用，但是Taichi Function 不能被 python 调用。（<strong>device</strong> functions；<strong>global</strong> kernels）</p>
<p>Taichi functions can be called by Taichi kernels and other Taichi functions. They must be decorated with @ti.func.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ti.func</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">triple</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> x * <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">triple_array</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">128</span>):</span><br><span class="line">        a[i] = triple(a[i])</span><br></pre></td></tr></table></figure>

<p>Taichi Function will be force-inlined(不通过压栈的方式调用，将函数体直接插入调用处). 暂时不支持递归。一个Taichi Function最多只能包含一条return statement。</p>
<h3 id="Matrices-and-linear-algebra"><a href="#Matrices-and-linear-algebra" class="headerlink" title="Matrices and linear algebra"></a>Matrices and linear algebra</h3><ul>
<li>ti.Matrix is for small matrices(e.g. 3x3) only.</li>
<li>ti.Vector is the same as ti.Matrix, except that it has only one column.</li>
</ul>
<p><strong>Note:</strong>  Differentiate element-wise product * and matrix product @</p>
<h4 id="Parallel-for-loops"><a href="#Parallel-for-loops" class="headerlink" title="Parallel for-loops"></a>Parallel for-loops</h4><p>For loops in Taichi have two forms:</p>
<ul>
<li><strong>Range-for loops</strong>, which are no different from Python for loops, except that it will be parallelized when used at the outermost scope. Range-for loops can be nested.</li>
<li><strong>Struct-for loops</strong>, which iterates over (sparse) tensor elements. </li>
</ul>
<p>For loops at the outermost scope in a Taichi kernel is <strong>automatically parallelized</strong>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fill</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):  <span class="comment"># Parallelized</span></span><br><span class="line">        x[i] += i</span><br><span class="line">        </span><br><span class="line">        s = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">5</span>):  <span class="comment"># Serialized in each parallel thread</span></span><br><span class="line">            s += j</span><br><span class="line">         </span><br><span class="line">        y[i] = s</span><br><span class="line">      </span><br><span class="line"><span class="meta">@ti,kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fill_3d</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># Parallelized for all 3&lt;=i&lt;8, 1&lt;=j&lt;6, 0&lt;=k&lt;9</span></span><br><span class="line">    <span class="keyword">for</span> i, j, k <span class="keyword">in</span> ti.ndrange((<span class="number">3</span>, <span class="number">8</span>), (<span class="number">1</span>, <span class="number">6</span>), <span class="number">9</span>):</span><br><span class="line">        x[i, j, k] = i + j + k</span><br></pre></td></tr></table></figure>

<p><strong>Note:</strong> It is the loop at the outermost scope that gets parallelized, not the outermost loop.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>): <span class="comment"># Parallelized</span></span><br><span class="line">        ...</span><br><span class="line">      </span><br><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bar</span><span class="params">(k: ti.i32)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> k &gt; <span class="number">42</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>): <span class="comment"># Serical</span></span><br><span class="line">            ...</span><br></pre></td></tr></table></figure>

<h4 id="Struct-for-loops"><a href="#Struct-for-loops" class="headerlink" title="Struct-for loops"></a>Struct-for loops</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> taichi <span class="keyword">as</span> ti</span><br><span class="line"></span><br><span class="line">ti.init(arch=ti.gpu)</span><br><span class="line"></span><br><span class="line">n = <span class="number">320</span></span><br><span class="line">pixels = ti.var(dt=ti.f32, shape=(n * <span class="number">2</span>, n))</span><br><span class="line"></span><br><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">paint</span><span class="params">(t: ti.f32)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i, j <span class="keyword">in</span> pixels:  <span class="comment"># Parallelized over all pixels</span></span><br><span class="line">        pixels[i, j] = i * <span class="number">0.001</span> + j * <span class="number">0.002</span> + t</span><br><span class="line">        </span><br><span class="line">paint(<span class="number">0</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>

<h3 id="Atomic-Operations"><a href="#Atomic-Operations" class="headerlink" title="Atomic Operations"></a>Atomic Operations</h3><p>In Taichi, augmented assignments (e.g.  x[i] += 1) are automatically atomic.</p>
<p>When modifying global variables in parallel, make sure you use atomic operations.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum</span><span class="params">()</span>:</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> x:</span><br><span class="line">	<span class="comment"># Approach 1: OK</span></span><br><span class="line">	total[<span class="literal">None</span>] += x[i]  <span class="comment"># total 0-D tensor</span></span><br><span class="line">    </span><br><span class="line">	<span class="comment"># Approach 2: OK</span></span><br><span class="line">	ti.atomic_add(total[<span class="literal">None</span>], x[i])</span><br><span class="line">    </span><br><span class="line">	<span class="comment"># Approach 3: Wrong result (the operation is not atomic .)</span></span><br><span class="line">	total[<span class="literal">None</span>] = total[<span class="literal">None</span>] + x[i]</span><br></pre></td></tr></table></figure>

<h3 id="Taichi-scope-v-s-Python-scope"><a href="#Taichi-scope-v-s-Python-scope" class="headerlink" title="Taichi-scope v.s. Python-scope"></a>Taichi-scope v.s. Python-scope</h3><p><strong>Definition：</strong></p>
<ul>
<li>Taichi-scope: Everything decorated with ti.kernel and ti.func.</li>
<li>Python-scope: Code outside the Taichi-scope.</li>
</ul>
<p><strong>Note：</strong></p>
<ul>
<li>Code in Taichi-scope will be compiled by the Taichi compiler and run on parallel devices.</li>
<li>Code in Python-scope is simply Python code and will be executed by the Python interpreter.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> taichi <span class="keyword">as</span> ti</span><br><span class="line">ti.init()</span><br><span class="line"></span><br><span class="line">a = ti.var(dt=ti.f32, shape=(<span class="number">42</span>, <span class="number">63</span>)) <span class="comment"># A tensor of 42x63 scalars</span></span><br><span class="line">b = ti.Vector(<span class="number">3</span>, dt=ti.f32, shape=<span class="number">4</span>) <span class="comment"># A tensor of 4x3D vectors</span></span><br><span class="line">C = ti.Matrix(<span class="number">2</span>, <span class="number">2</span>, dt=ti.f32, shape=(<span class="number">3</span>,<span class="number">5</span>)) <span class="comment"># A tensor of 3x5 2x2 matrices</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foo</span><span class="params">()</span>:</span></span><br><span class="line">    a[<span class="number">3</span>, <span class="number">4</span>] = <span class="number">1</span></span><br><span class="line">    print(<span class="string">'a[3, 4] ='</span>, a[<span class="number">3</span>, <span class="number">4</span>]) </span><br><span class="line">    <span class="comment"># a[3, 4] = 1.000000</span></span><br><span class="line">    </span><br><span class="line">    b[<span class="number">2</span>] = [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line">    print(<span class="string">'b[0] ='</span>, b[<span class="number">0</span>], <span class="string">', b[2] ='</span>, b[<span class="number">2</span>])</span><br><span class="line">    <span class="comment"># b[0] = [0.000000, 0.000000, 0.000000] , b[2] = [6.000000, 7.000000, 8.000000]</span></span><br><span class="line">    </span><br><span class="line">    C[<span class="number">2</span>, <span class="number">1</span>][<span class="number">0</span>, <span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">    print(<span class="string">'C[2, 1] ='</span>, C[<span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line">    <span class="comment"># C[2, 1] = [[0.000000, 1.000000], [0.000000, 0.000000]]</span></span><br><span class="line">    </span><br><span class="line">foo()</span><br></pre></td></tr></table></figure>

<h3 id="Phases-of-a-Taichi-program"><a href="#Phases-of-a-Taichi-program" class="headerlink" title="Phases of a Taichi program"></a>Phases of a Taichi program</h3><ol>
<li>Initialization: ti.init(…)</li>
<li>Tensor allocation: ti.var, ti.Vector, ti.Matrix</li>
<li>Computation (launch kernels, access tensors in Python-scope)</li>
<li>Optional: restart the Taichi system (clear memory, destroy all variables and kernels): ti.reset()</li>
</ol>
<p><strong>Note</strong></p>
<p>For now, after the first kernel launch or tensor access in Python-scope, no more tensor allocation is allowed.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># fractal.py</span></span><br><span class="line"><span class="keyword">import</span> taichi <span class="keyword">as</span> ti</span><br><span class="line">ti.init(arch=ti.gpu)</span><br><span class="line"></span><br><span class="line">n = <span class="number">320</span></span><br><span class="line">pixels = ti.var(dt=ti.f32, shape=(n * <span class="number">2</span>, n))</span><br><span class="line"></span><br><span class="line"><span class="meta">@ti.func</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">complex_sqr</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> ti.Vector([z[<span class="number">0</span>]**<span class="number">2</span> - z[<span class="number">1</span>]**<span class="number">2</span>, z[<span class="number">1</span>]*z[<span class="number">0</span>]*<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">paint</span><span class="params">(t: ti.f32)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i, j <span class="keyword">in</span> pixels: <span class="comment"># Parallelized over all pixels</span></span><br><span class="line">        c = ti.Vector([<span class="number">-0.8</span>, ti.cos(t)*<span class="number">0.2</span>])</span><br><span class="line">        z = ti.Vector([i/n<span class="number">-1</span>, j/n<span class="number">-0.5</span>]) * <span class="number">2</span></span><br><span class="line">        iterations = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> z.norm() &lt; <span class="number">20</span> <span class="keyword">and</span> iterations &lt;<span class="number">50</span>:</span><br><span class="line">            z = complex_sqr(z) + c</span><br><span class="line">            iterations += <span class="number">1</span></span><br><span class="line">        pixels[i, j] = <span class="number">1</span> - iterations * <span class="number">0.02</span></span><br><span class="line">        </span><br><span class="line">gui = ti.GUI(<span class="string">"Julia Set"</span>, res=(n*<span class="number">2</span>, n))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000000</span>):</span><br><span class="line">    paint(i * <span class="number">0.03</span>)</span><br><span class="line">    gui.set_image(pixels)</span><br><span class="line">    gui.show()</span><br></pre></td></tr></table></figure>

<h2 id="Debugging"><a href="#Debugging" class="headerlink" title="Debugging"></a>Debugging</h2><h3 id="Debug-mode"><a href="#Debug-mode" class="headerlink" title="Debug mode"></a>Debug mode</h3><p> ti.init(debug=True, arch=ti.cpu) initializes Taichi in debug mode, which enables bound checkers (CPU only).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> taichi <span class="keyword">as</span> ti</span><br><span class="line">ti.init(debug=<span class="literal">True</span>, arch=ti.cpu)</span><br><span class="line"></span><br><span class="line">a = ti.var(ti.i32, shape=(<span class="number">10</span>))</span><br><span class="line">b = ti.var(ti.i32, shape=(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shift</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        a[i] = b[i+<span class="number">1</span>] <span class="comment"># Runtime error in debug mode</span></span><br><span class="line">        </span><br><span class="line">shift()</span><br></pre></td></tr></table></figure>

<h2 id="Objective-data-oriented-programming"><a href="#Objective-data-oriented-programming" class="headerlink" title="Objective data-oriented programming"></a>Objective data-oriented programming</h2><p>Taichi is a data-oriented programming (DOP) language, but simple DOP makes modularization hard. To improve code reusability, Taichi borrows some concepts from object-oriented programming (OOP).</p>
<p>The hybrid scheme is called objective data-oriented programming (ODOP).</p>
<p>Three important decorators</p>
<ul>
<li>Use @ti.data_oriented to decorate your class.</li>
<li>Use @ti.kernel to decorate class members functions that are Taichi kernels.</li>
<li>Use @ti.func to decorate class members functions that are Taichi functions.</li>
</ul>
<p>Demo:  ti example odop_solar  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> taichi <span class="keyword">as</span> ti</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line">ti.init()</span><br><span class="line"></span><br><span class="line"><span class="meta">@ti.data_oriented</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SolarSystem</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n, dt)</span>:</span></span><br><span class="line">        <span class="comment"># initializer of the solar system simulator</span></span><br><span class="line">        self.n = n</span><br><span class="line">        self.dt = dt</span><br><span class="line">        self.x = ti.Vector.field(<span class="number">2</span>, dtype=float, shape=n)</span><br><span class="line">        self.v = ti.Vector.field(<span class="number">2</span>, dtype=float, shape=n)</span><br><span class="line">        self.center = ti.Vector.field(<span class="number">2</span>, dtype=float, shape=())</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line"><span class="meta">    @ti.func</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">random_vector_in</span><span class="params">(rmax)</span>:</span></span><br><span class="line">        <span class="comment"># create a random vector</span></span><br><span class="line">        a = ti.random() * math.tau</span><br><span class="line">        r = ti.random() * rmax</span><br><span class="line">        <span class="keyword">return</span> r * ti.Vector([ti.cos(a), ti.sin(a)])</span><br><span class="line"></span><br><span class="line"><span class="meta">    @ti.kernel</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initialize</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># initialization or reset</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.n):</span><br><span class="line">            offset = self.random_vector_in(<span class="number">0.5</span>)</span><br><span class="line">            self.x[i] = self.center[<span class="literal">None</span>] + offset  <span class="comment"># Offset from center</span></span><br><span class="line">            self.v[i] = [-offset.y, offset.x]  <span class="comment"># Perpendicular to offset</span></span><br><span class="line">            self.v[i] += self.random_vector_in(<span class="number">0.02</span>)  <span class="comment"># Shaking</span></span><br><span class="line">            self.v[i] *= <span class="number">1</span> / offset.norm()**<span class="number">1.5</span>  <span class="comment"># Kepler's 3rd law</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @ti.func</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gravity</span><span class="params">(self, pos)</span>:</span></span><br><span class="line">        <span class="comment"># compute gravitational acceleration at pos</span></span><br><span class="line">        offset = -(pos - self.center[<span class="literal">None</span>])</span><br><span class="line">        <span class="keyword">return</span> offset / offset.norm()**<span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @ti.kernel</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">integrate</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># semi-implicit time integration</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.n):</span><br><span class="line">            self.v[i] += self.dt * self.gravity(self.x[i])</span><br><span class="line">            self.x[i] += self.dt * self.v[i]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">render</span><span class="params">(self, gui)</span>:</span></span><br><span class="line">        <span class="comment"># render the simulation scene on the GUI</span></span><br><span class="line">        gui.circle([<span class="number">0.5</span>, <span class="number">0.5</span>], radius=<span class="number">10</span>, color=<span class="number">0xffaa88</span>)</span><br><span class="line">        gui.circles(solar.x.to_numpy(), radius=<span class="number">3</span>, color=<span class="number">0xffffff</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">solar = SolarSystem(<span class="number">8</span>, <span class="number">0.0001</span>)</span><br><span class="line">solar.center[<span class="literal">None</span>] = [<span class="number">0.5</span>, <span class="number">0.5</span>]</span><br><span class="line">solar.initialize()</span><br><span class="line"></span><br><span class="line">gui = ti.GUI(<span class="string">"Solar System"</span>, background_color=<span class="number">0x0071a</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> gui.running:</span><br><span class="line">    <span class="comment"># GUI event processing</span></span><br><span class="line">    <span class="keyword">if</span> gui.get_event(gui.PRESS):</span><br><span class="line">        <span class="keyword">if</span> gui.event.key == gui.SPACE:</span><br><span class="line">            solar.initialize()</span><br><span class="line">        <span class="keyword">elif</span> gui.event.key == gui.ESCAPE:</span><br><span class="line">            gui.running = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        solar.integrate()</span><br><span class="line"></span><br><span class="line">    solar.render(gui)</span><br><span class="line">    gui.show()</span><br></pre></td></tr></table></figure>

<h2 id="Metaprogramming"><a href="#Metaprogramming" class="headerlink" title="Metaprogramming"></a>Metaprogramming</h2><p>Taichi provides metaprogramming tools. Metaprogramming can :</p>
<ul>
<li>Allow users to pass almost anything (including Taichi tensors) to Taichi kernels</li>
<li>Improve run-time performance by moving run-time costs to compile time</li>
<li>Achieve dimensionality independence (e.g. write 2D and 3D simulation code simultaneously.)</li>
<li>Simplify the development of Taichi standard library</li>
</ul>
<p>Taichi kernels are <strong>lazily instantiated</strong> and a lot of computation can happen at compile time. Every kernel in Taichi is a template kernel, even if it has no template arguments.</p>
<h3 id="Templates"><a href="#Templates" class="headerlink" title="Templates"></a>Templates</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">copy</span><span class="params">(x: ti.template <span class="params">()</span>, y: ti.template <span class="params">()</span>, c: ti.f32)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> x:   </span><br><span class="line">        y[i] = x[i] + c</span><br></pre></td></tr></table></figure>

<p>如果不用template很难把tensor当argument传给kernel</p>
<p><strong>Template instantiation</strong></p>
<p>Kernel templates will be instantiated on the first call, and cached for later calls with the same template signature.</p>
<p><strong>Template argument takes (almost) everything</strong></p>
<p>Feel free to pass tensors, classes, functions, and numerical values to ti.template() arguments.</p>
<h3 id="Template-kernel-instantiation"><a href="#Template-kernel-instantiation" class="headerlink" title="Template kernel instantiation"></a>Template kernel instantiation</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> taichi <span class="keyword">as</span> ti</span><br><span class="line">ti.init()</span><br><span class="line"></span><br><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello</span><span class="params">(i: ti.template <span class="params">()</span>)</span>:</span></span><br><span class="line">    print(i)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range (<span class="number">100</span>):</span><br><span class="line">    hello(i) <span class="comment"># 100 different kernels will be created</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">world</span><span class="params">(i: ti.i32)</span>:</span></span><br><span class="line">    print(i)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range (<span class="number">100</span>):</span><br><span class="line">    world(i) <span class="comment"># The only instance will be reused</span></span><br></pre></td></tr></table></figure>

<h3 id="Dimensionality-independent-programming"><a href="#Dimensionality-independent-programming" class="headerlink" title="Dimensionality-independent programming"></a>Dimensionality-independent programming</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">copy</span><span class="params">(x: ti.template<span class="params">()</span>, y: ti.template<span class="params">()</span>)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> I <span class="keyword">in</span> ti.grouped(y):  <span class="comment"># 将y的全部index打包,I--&gt;n维向量</span></span><br><span class="line">        x[I] = y[I]</span><br><span class="line">        </span><br><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">array_op</span><span class="params">(x: ti.template<span class="params">()</span>, y: ti.template<span class="params">()</span>)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> I <span class="keyword">in</span> ti.grouped(x):</span><br><span class="line">        <span class="comment"># I is a vector of size x.dim() and data type i32</span></span><br><span class="line">        y[I] = I[<span class="number">0</span>] + I[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># If tensor x is 2D, the above is equivalent to</span></span><br><span class="line">    <span class="keyword">for</span> i, j <span class="keyword">in</span> x:</span><br><span class="line">        y[i, j] = i + j</span><br></pre></td></tr></table></figure>

<h3 id="Tensor-size-reflection"><a href="#Tensor-size-reflection" class="headerlink" title="Tensor-size reflection"></a>Tensor-size reflection</h3><p>Fetch tensor dimensionality info as compile-time constants:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> taichi <span class="keyword">as</span> ti</span><br><span class="line"></span><br><span class="line">tensor = ti.var(ti.f32, shape=(<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">64</span>))</span><br><span class="line"></span><br><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_tensor_size</span><span class="params">(x: ti.template<span class="params">()</span>)</span>:</span></span><br><span class="line">    print(len(x.shape))  <span class="comment"># x.dim() &amp; x.shape() is deprecated</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> ti.static(range(len(x.shape))):</span><br><span class="line">        print(x.shape[i])</span><br><span class="line"></span><br><span class="line">print_tensor_size(tensor)</span><br></pre></td></tr></table></figure>

<h3 id="Compile-time-branching"><a href="#Compile-time-branching" class="headerlink" title="Compile-time branching"></a>Compile-time branching</h3><p>Using compile-time evaluation will allow certain computations to happen when kernels are being instantiated. This saves the overhead of those computations at runtime. (C++17 equivalence: if constexpr.)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">enable_projection = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">static</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">if</span> ti.static(enable_projection): <span class="comment"># No runtime overhead</span></span><br><span class="line">        x[<span class="number">0</span>] = <span class="number">1</span></span><br></pre></td></tr></table></figure>

<h3 id="Forced-loop-unrolling"><a href="#Forced-loop-unrolling" class="headerlink" title="Forced loop-unrolling"></a>Forced loop-unrolling</h3><p>Use ti.static(range(…)) to unroll the loops at compile time:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> taichi <span class="keyword">as</span> ti</span><br><span class="line"></span><br><span class="line">ti.init()</span><br><span class="line">x = ti.Vector(<span class="number">3</span>, dt=ti.i32, shape =<span class="number">16</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fill</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> x:</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> ti.static(range(<span class="number">3</span>)):</span><br><span class="line">            x[i][j] = j</span><br><span class="line">        print(x[i])</span><br><span class="line"></span><br><span class="line">fill()</span><br></pre></td></tr></table></figure>

<p>When to use range-for loops?</p>
<ul>
<li>For performance.  （loop-unrolling后可以减少loop本身的overhead）</li>
<li>To loop over vector/matrix elements. Indices into Taichi matrices must be compile-time constants. Indices into Taichi tensors can be run-time variables. For example, if x is a 1-D tensor of 3D vectors, accessed as x [tensor_index] [matrix_index]. The first index can be a variable, yet the second must be a constant.</li>
</ul>
<h3 id="Variable-aliasing"><a href="#Variable-aliasing" class="headerlink" title="Variable aliasing"></a>Variable aliasing</h3><p>Creating handy aliases for global variables and functions with cumbersome names can sometimes improve readability:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_kernel</span> <span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i, j <span class="keyword">in</span> tensor_a:</span><br><span class="line">        tensor_b[i, j] = some_function(tensor_a[i, j])</span><br><span class="line">        </span><br><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_kernel</span> <span class="params">()</span>:</span></span><br><span class="line">    a, b, fun = ti.static(tensor_a , tensor_b , some_function)</span><br><span class="line">    <span class="keyword">for</span> i,j <span class="keyword">in</span> a:</span><br><span class="line">        b[i,j] = fun(a[i,j])</span><br></pre></td></tr></table></figure>

<h2 id="Differentiable-Programming"><a href="#Differentiable-Programming" class="headerlink" title="Differentiable Programming"></a>Differentiable Programming</h2><p>Forward programs evaluate $f(x)$, differentiable programs evaluate $\frac{∂f(x)}{∂x}$</p>
<p>Taichi supports <strong>reverse-mode automatic differentiation (AutoDiff)</strong> that back-propagates gradients w.r.t. a scalar (loss) function f(x).</p>
<p>Two ways to compute gradients:</p>
<ol>
<li>Use Taichi’s tape (ti.Tape(loss)) for both forward and gradient evaluation.</li>
<li>Explicitly use gradient kernels for gradient evaluation with more controls.</li>
</ol>
<h3 id="Gradient-based-optimization"><a href="#Gradient-based-optimization" class="headerlink" title="Gradient-based optimization"></a>Gradient-based optimization</h3><p>$$<br>min_x \quad L(x) = \frac{1}{2}\sum_{i=0}^{n-1}(x_i - y_i)^2<br>$$</p>
<ol>
<li><p>Allocating tensors with gradients：x = ti.var(dt=ti.f32, shape=n, needs_grad=True)</p>
</li>
<li><p>Defining loss function kernel(s)：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduce</span> <span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        L[<span class="literal">None</span>] += <span class="number">0.5</span> * (x[i] - y[i])**<span class="number">2</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Compute loss with ti.Tape(loss=L)：reduce()</p>
</li>
<li><p>Gradient descent：for i in x: x[i] -= x.grad[i] * 0.1</p>
</li>
</ol>
<h3 id="Application-1-Forces-from-potential-energy-gradients"><a href="#Application-1-Forces-from-potential-energy-gradients" class="headerlink" title="Application 1: Forces from potential energy gradients"></a>Application 1: Forces from potential energy gradients</h3><p>From the definition of potential energy: (potential energy关于位置的导数–&gt;顶点的受力)<br>$$<br>f_i = -\frac{∂U(x)}{∂x_i}<br>$$<br>Manually deriving gradients is hard. Let’s use AutoDiff:</p>
<ol>
<li>Allocate a 0−D tensor to store the potential energy: potential = ti.var(ti.f32, shape=()).</li>
<li>Define forward kernels that computes potential energy from x[i].</li>
<li>In a ti.Tape(loss=potential), call the forward kernels.</li>
<li>Force on each particle is -x.grad[i].</li>
</ol>
<h3 id="Application-2-Differentiating-a-whole-physical-process"><a href="#Application-2-Differentiating-a-whole-physical-process" class="headerlink" title="Application 2: Differentiating a whole physical process"></a>Application 2: Differentiating a whole physical process</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> ti.Tape(loss=loss):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(steps - <span class="number">1</span>):</span><br><span class="line">        simulate(i)</span><br></pre></td></tr></table></figure>

<p><strong>Computational history</strong></p>
<p>Always keep the whole computational history of time steps for end-to-end differentiation. I.e., instead of only allocating<br>ti.Vector(3, dt=ti.f32, shape=(num_particles)) that stores the latest particles, allocate for the whole simulation process<br>ti.Vector(3, dt=ti.f32, shape=(num_timesteps, num_particles)). (Use checkpointing (later in this course) to reduce memory consumption.)</p>
<h2 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h2><p><strong>Visualizing 2D results</strong></p>
<p>Simply make use of Taichi’s GUI system. Useful functions:</p>
<ul>
<li>gui = ti.GUI(“Taichi MLS-MPM-128”, res=512, background_color=0x112F41)</li>
<li>gui.circle/gui.circles(x.to_numpy(), radius=1.5, color=colors.to_numpy())</li>
<li>gui.line/triangle/set_image/show/…</li>
</ul>
<p><strong>Visualizing 3D results</strong></p>
<p>Exporting 3D particles and meshes using ti.PLYWriter</p>
<p>Use Houdini/Blender to view (and render) your 3D results.</p>
<hr>
<p>ti example: 查看example demo 4</p>
<p>python -m taichi example mpm128 (demo_name)</p>
<h1 id="2、Lagrangian-Simulation-Approaches"><a href="#2、Lagrangian-Simulation-Approaches" class="headerlink" title="2、Lagrangian Simulation Approaches"></a>2、Lagrangian Simulation Approaches</h1><h2 id="Mass-Spring-Systems-弹簧质点系统"><a href="#Mass-Spring-Systems-弹簧质点系统" class="headerlink" title="Mass-Spring Systems (弹簧质点系统)"></a>Mass-Spring Systems (弹簧质点系统)</h2><img src="https://hexo-1257922593.cos.ap-beijing.myqcloud.com/taichi/mass_spring.png" alt="mass_spring" style="zoom:50%;" />

<p>k: spring stiffness; l<sub>ij</sub>: spring rest length between particle i and particle j;</p>
<p>m<sub>i</sub>: the mass of particle i. (<strong>x<sub>i</sub></strong> − <strong>x<sub>j</sub></strong>): direction vector from particle j to particle i;</p>
<h2 id="Time-integration"><a href="#Time-integration" class="headerlink" title="Time integration"></a>Time integration</h2><p><strong>1、Forward Euler</strong> (explicit)：</p>
<p>​        前向欧拉法：根据现有的状态推测以后的状态：</p>
<p>$$<br>v_{t+1} = v_t + \Delta t\frac{f_t}{m}<br>$$</p>
<p>$$<br>x_{t+1} = x_t + \Delta tv_t<br>$$</p>
<p><strong>2、Semi-implicit Euler</strong> (aka. symplectic Euler, explicit)：<br>$$<br>v_{t+1} = v_t + \Delta t\frac{f_t}{m}<br>$$</p>
<p>$$<br>x_{t+1} = x_t + \Delta tv_{t+1}<br>$$</p>
<p><strong>3、Backward Euler</strong> (often with Newton’s method, implicit)：</p>
<h3 id="Implementing-a-mass-spring-system-with-symplectic-Euler"><a href="#Implementing-a-mass-spring-system-with-symplectic-Euler" class="headerlink" title="Implementing a mass-spring system with symplectic Euler"></a>Implementing a mass-spring system with symplectic Euler</h3><ol>
<li><p>Compute new velocity using<br>$$<br>v_{t+1} = v_t + \Delta t\frac{f_t}{m}<br>$$</p>
</li>
<li><p>Collision with ground</p>
</li>
<li><p>Compute new position using<br>$$<br>x_{t+1} = x_t + \Delta tv_{t+1}<br>$$</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mass_spring.py</span></span><br><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">substep</span><span class="params">()</span>:</span></span><br><span class="line">    n = num_particles[<span class="literal">None</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute force and new velocity</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        v[i] *= ti.exp(-dt * damping[<span class="literal">None</span>]) <span class="comment"># damping</span></span><br><span class="line">        total_force = ti.Vector(gravity) * particle_mass</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">            <span class="keyword">if</span> rest_length[i, j] != <span class="number">0</span>:</span><br><span class="line">                x_ij = x[i] - x[j]</span><br><span class="line">                total_force += -spring_stiffness[<span class="literal">None</span>] * (x_ij.norm() - rest_length[i, j]) * x_ij.normalized()</span><br><span class="line">        v[i] += dt * total_force / particle_mass</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># Collide with ground</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="keyword">if</span> x[i].y &lt; bottom_y:</span><br><span class="line">            x[i].y = bottom_y</span><br><span class="line">            v[i].y = <span class="number">0</span></span><br><span class="line">            </span><br><span class="line">    <span class="comment"># Compute new position</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        x[i] += v[i] * dt</span><br></pre></td></tr></table></figure>

<h3 id="Explicit-v-s-implicit-time-integrators"><a href="#Explicit-v-s-implicit-time-integrators" class="headerlink" title="Explicit v.s. implicit time integrators"></a>Explicit v.s. implicit time integrators</h3><p>Explicit (forward Euler, symplectic Euler, RK, …)：</p>
<ul>
<li><p>Future depends only on past</p>
</li>
<li><p>Easy to implement</p>
</li>
<li><p>Easy to explode: （从材料的刚度考虑时间步长的限制）<br>$$<br>\Delta t \leq c\sqrt{\frac{m}{k}} \quad\quad(c-1)<br>$$</p>
</li>
<li><p>Bad for stiff materials</p>
</li>
</ul>
<p>Implicit (backward Euler, middle-point, …):</p>
<ul>
<li>Future depends on both future and past</li>
<li>Chicken-egg problem: need to solve a system of (linear) equations</li>
<li>In general harder to implement</li>
<li>Each step is more expensive but time steps are larger</li>
<li>Numerical damping and locking</li>
</ul>
<h3 id="Mass-spring-systems"><a href="#Mass-spring-systems" class="headerlink" title="Mass-spring systems"></a>Mass-spring systems</h3><p>Implicit time integration:<br>$$<br>x_{t+1} = x_t + \Delta tv_{t+1} \quad\quad (1)<br>$$</p>
<p>$$<br>v_{t+1} = v_t + \Delta tM^{-1}f(x_{t+1}) \quad\quad (2)<br>$$</p>
<p>Eliminate x<sub>t+1</sub>:<br>$$<br>v_{t+1} = v_t + \Delta tM^{-1}f(x_t + \Delta tv_{t+1}) \quad\quad (3)<br>$$<br>Linearize (one step of Newton’s method):<br>$$<br>v_{t+1} = v_t + \Delta tM^{-1}[f(x_t) + \frac{∂f}{∂x}(x_t)\Delta tv_{t+1}] \quad\quad (4)<br>$$<br>Clean up:<br>$$<br>[I - \Delta t^2M^{-1}\frac{∂f}{∂x}(x_t)] v_{t+1} = v_t + \Delta tM^{-1}f(x_t) \quad\quad (5)<br>$$<br>How to solve it?</p>
<ul>
<li>Jacobi/Gauss-Seidel iterations (easy to implement!)</li>
<li>Conjugate gradients (later in this course)</li>
</ul>
<p>$$<br>A = [I - \Delta t^2M^{-1}\frac{∂f}{∂x}(x_t)]<br>$$</p>
<p>$$<br>b = v_t + \Delta tM^{-1}f(x_t)<br>$$</p>
<p>$$<br>Av_{t+1} = b<br>$$</p>
<h3 id="Solving-linear-systems-with-Jacobi-iterations"><a href="#Solving-linear-systems-with-Jacobi-iterations" class="headerlink" title="Solving linear systems with Jacobi iterations"></a>Solving linear systems with Jacobi iterations</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> taichi <span class="keyword">as</span> ti</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">ti.init()</span><br><span class="line"></span><br><span class="line">n = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">A = ti.var(dt=ti.f32, shape=(n, n))</span><br><span class="line">x = ti.var(dt=ti.f32, shape=n)</span><br><span class="line">new_x = ti.var(dt=ti.f32, shape=n)</span><br><span class="line">b = ti.var(dt=ti.f32, shape=n)</span><br><span class="line"></span><br><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">iterate</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        r = b[i]</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">            <span class="keyword">if</span> i != j:</span><br><span class="line">                r -= A[i, j] * x[j]</span><br><span class="line">                </span><br><span class="line">        new_x[i] = r / A[i, i]</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        x[i] = new_x[i]</span><br><span class="line"></span><br><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">residual</span><span class="params">()</span> -&gt; ti.f32:</span></span><br><span class="line">    res = <span class="number">0.0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        r = b[i] * <span class="number">1.0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">            r -= A[i, j] * x[j]</span><br><span class="line">        res += r * r</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        A[i, j] = random.random() - <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">    A[i, i] += n * <span class="number">0.1</span></span><br><span class="line">    </span><br><span class="line">    b[i] = random.random() * <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    iterate()</span><br><span class="line">    print(<span class="string">f'iter <span class="subst">&#123;i&#125;</span>, residual=<span class="subst">&#123;residual():<span class="number">0.10</span>f&#125;</span>'</span>)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">    lhs = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        lhs += A[i, j] * x[j]</span><br><span class="line">    <span class="keyword">assert</span> abs(lhs - b[i]) &lt; <span class="number">1e-4</span></span><br></pre></td></tr></table></figure>

<h3 id="Unifying-explicit-and-implicit-integrators"><a href="#Unifying-explicit-and-implicit-integrators" class="headerlink" title="Unifying explicit and implicit integrators"></a>Unifying explicit and implicit integrators</h3><p>$$<br>[I - \beta\Delta t^2M^{-1}\frac{∂f}{∂x}(x_t)] v_{t+1} = v_t + \Delta tM^{-1}f(x_t)<br>$$</p>
<ol>
<li>β = 0: forward/semi-implicit Euler (explicit)</li>
<li>β = 1/2: middle-point (implicit)</li>
<li>β = 1: backward Euler (implicit)</li>
</ol>
<h2 id="Lagrangian-fluid-simulation-SPH"><a href="#Lagrangian-fluid-simulation-SPH" class="headerlink" title="Lagrangian fluid simulation: SPH"></a>Lagrangian fluid simulation: SPH</h2><p><strong>High-level idea:</strong> use particles carrying samples of physical quantities, and a kernel function W, to approximate continuous fields: (<em>A</em> can be almost any spatially varying physical attributes: density, pressure, etc. Derivatives: different story)<br>$$<br>A(x) = \sum_i{A_i}\frac{m_i}{ρ_i}W(||x-x_j||_2, h)<br>$$</p>
<ol>
<li>Originally proposed for astrophysical problems</li>
<li>No meshes. Very suitable for free-surface flows!</li>
<li>Easy to understand intuitively: just imagine each particle is a small parcel of water (although strictly not the case!)</li>
</ol>
<h3 id="Implementing-SPH-using-the-Equation-of-States"><a href="#Implementing-SPH-using-the-Equation-of-States" class="headerlink" title="Implementing SPH using the Equation of States"></a>Implementing SPH using the Equation of States</h3><p>Also known as Weakly Compressible SPH (WCSPH).</p>
<p>Momentum equation: ( ρ: density;  B: bulk modulus;  γ : constant, usually ∼ 7 )<br>$$<br>\frac{Dv}{Dt} = -\frac{1}{ρ}\nabla p + g, \quad\quad p = B((\frac{ρ}{ρ_0})^\gamma - 1)<br>$$</p>
<p>$$<br>A(x) = \sum_i{A_i}\frac{m_i}{ρ_i}W(||x-x_j||_2,h)<br>$$</p>
<p>$$<br>ρ_i = \sum_j{m_j}W(||x_i-x_j||_2,h)<br>$$</p>
<p>Extras: surface tension, viscosity</p>
<p>Note: the WCSPH paper should have used material derivatives.</p>
<h3 id="Gradients-in-SPH"><a href="#Gradients-in-SPH" class="headerlink" title="Gradients in SPH"></a>Gradients in SPH</h3><p>$$<br>\nabla A_i = ρ<em>i \sum{m_j}(\frac{A_i}{ρ_i^2} + \frac{A_j}{ρ_j^2}) \nabla</em>{x_i}W(||x_i-x_j||_2,h)<br>$$</p>
<p>Not really accurate.</p>
<p>But at least symmetric and momentum conserving!</p>
<h3 id="SPH-Simulation-Cycle"><a href="#SPH-Simulation-Cycle" class="headerlink" title="SPH Simulation Cycle"></a>SPH Simulation Cycle</h3><p>$$<br>\frac{Dv}{Dt} = -\frac{1}{ρ}\nabla p + g, \quad\quad p = B((\frac{ρ}{ρ_0})^\gamma - 1)<br>$$</p>
<ol>
<li>For each particle i, compute $ρ_i = \sum{m_j}W(||x_i-x_j||_2,h)$</li>
<li>For each particle i, compute $\nabla p_i$ using the gradient operator</li>
<li>Symplectic Euler step (again…):</li>
</ol>
<p>$$<br>v_{t+1} = v_t + \Delta t\frac{D_v}{D_t}<br>$$</p>
<p>$$<br>x_{t+1} = x_t + \Delta tv_{t+1}<br>$$</p>
<h3 id="Variants-of-SPH"><a href="#Variants-of-SPH" class="headerlink" title="Variants of SPH"></a>Variants of SPH</h3><p>Predictive-Corrective Incompressible SPH (PCI-SPH)：隐式的时间积分（不完全隐式），采用预测矫正的格式，每次先预测一下粒子的位置/速度，然后根据预测做出矫正，得到一个散度比较小的速度场–&gt;更加接近不可压缩</p>
<p>Position-based fluids (PBF) Demo: ti example pbf2d</p>
<p>Divergence-free SPH (DFSPH)</p>
<h3 id="Courant–Friedrichs–Lewy-CFL-condition"><a href="#Courant–Friedrichs–Lewy-CFL-condition" class="headerlink" title="Courant–Friedrichs–Lewy (CFL) condition"></a>Courant–Friedrichs–Lewy (CFL) condition</h3><p>显示时间积分：从粒子运动的速度考虑时间步长的限制：<br>$$<br>C = \frac{u \Delta t}{\Delta x} \leq C_{max} - 1<br>$$</p>
<ul>
<li>C:  CFL number (Courant number, or simple the CFL)</li>
<li>$\Delta t$:  time step</li>
<li>$\Delta x$:  length interval (e.g. particle radius and grid size)</li>
<li>u: maximum (velocity)     $u\Delta t$  –&gt; 一个时间步之内粒子移动的最大距离</li>
</ul>
<p>Application: estimating allowed time step in (explicit) time integrations. Typical C<sub>max</sub> in graphics:</p>
<ul>
<li>SPH: ∼ 0.4</li>
<li>MPM: 0.3 ∼ 1</li>
<li>FLIP fluid (smoke): 1 ∼ 5+</li>
</ul>
<h3 id="Accelerating-SPH-Neighborhood-search"><a href="#Accelerating-SPH-Neighborhood-search" class="headerlink" title="Accelerating SPH: Neighborhood search"></a>Accelerating SPH: Neighborhood search</h3><p>So far, per substep complexity of SPH is $O(n^2)$ . This is too costly to be practical. In practice, people build spatial data structure such as voxel grids to accelerate neighborhood search. This reduces time complexity to O(n).</p>
<h1 id="3、Basics-of-deformation-elasticity-and-finite-elements"><a href="#3、Basics-of-deformation-elasticity-and-finite-elements" class="headerlink" title="3、Basics of deformation, elasticity, and finite elements"></a>3、Basics of deformation, elasticity, and finite elements</h1><h2 id="Deformation"><a href="#Deformation" class="headerlink" title="Deformation"></a>Deformation</h2><p>Deformation map ϕ : a (vector to vector) function that relates rest material position and deformed material position.  (将静止位置映射到形变位置，如果在3D中，即是从三维向量到三维向量的一个向量函数)<br>$$<br>x_{deformed} = \phi (x_{rest})<br>$$<br>Deformation gradient F：（对静止位置求导数）<br>$$<br>F:=\frac{∂x_{deformed}}{∂x_{rest}}<br>$$<br>Deformation gradients are translational invariant:<br>$$<br>\phi_1 = \phi(x_{rest}) \quad and \quad \phi_2 = \phi(x_{rest}) + c<br>$$<br>​        have the same deformation gradients</p>
<p>Deform/rest volume ratio $J = det(F)$   （$J$ ：形变以后的体积/静止的体积 = F的行列式）</p>
<h2 id="Elasticity"><a href="#Elasticity" class="headerlink" title="Elasticity"></a>Elasticity</h2><h3 id="Hyperelasticity"><a href="#Hyperelasticity" class="headerlink" title="Hyperelasticity"></a>Hyperelasticity</h3><p>Hyperelastic materials: materials whose stress–strain relationship is defined by a strain energy density function：<br>$$<br>\psi = \psi(F)<br>$$<br>Intuitive understanding: $\psi$ is a potential function that penalizes deformation.</p>
<p>“Stress”：the material’s internal elastic forces. （用来恢复原来体积形状的内力）</p>
<p>“Strain”：just replace it with deformation gradients F for now.</p>
<p><strong>Be careful</strong></p>
<p>We use ψ as the strain energy density function and ϕ as the deformation map. They are completely different.</p>
<h3 id="Stress-tensor"><a href="#Stress-tensor" class="headerlink" title="Stress tensor"></a>Stress tensor</h3>
    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/08/23/Weakly-compressible-SPH-for-free-surface-flows/" rel="prev" title="Weakly compressible SPH for free surface flows">
      <i class="fa fa-chevron-left"></i> Weakly compressible SPH for free surface flows
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1、The-Taichi-Programming-Language"><span class="nav-number">1.</span> <span class="nav-text">1、The Taichi Programming Language</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Data"><span class="nav-number">1.1.</span> <span class="nav-text">Data</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-types"><span class="nav-number">1.1.1.</span> <span class="nav-text">Data types</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tensors"><span class="nav-number">1.1.2.</span> <span class="nav-text">Tensors</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#computation"><span class="nav-number">1.2.</span> <span class="nav-text">computation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Kernels"><span class="nav-number">1.2.1.</span> <span class="nav-text">Kernels</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Functions"><span class="nav-number">1.2.2.</span> <span class="nav-text">Functions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Matrices-and-linear-algebra"><span class="nav-number">1.2.3.</span> <span class="nav-text">Matrices and linear algebra</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Parallel-for-loops"><span class="nav-number">1.2.3.1.</span> <span class="nav-text">Parallel for-loops</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Struct-for-loops"><span class="nav-number">1.2.3.2.</span> <span class="nav-text">Struct-for loops</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Atomic-Operations"><span class="nav-number">1.2.4.</span> <span class="nav-text">Atomic Operations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Taichi-scope-v-s-Python-scope"><span class="nav-number">1.2.5.</span> <span class="nav-text">Taichi-scope v.s. Python-scope</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Phases-of-a-Taichi-program"><span class="nav-number">1.2.6.</span> <span class="nav-text">Phases of a Taichi program</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Debugging"><span class="nav-number">1.3.</span> <span class="nav-text">Debugging</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Debug-mode"><span class="nav-number">1.3.1.</span> <span class="nav-text">Debug mode</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Objective-data-oriented-programming"><span class="nav-number">1.4.</span> <span class="nav-text">Objective data-oriented programming</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Metaprogramming"><span class="nav-number">1.5.</span> <span class="nav-text">Metaprogramming</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Templates"><span class="nav-number">1.5.1.</span> <span class="nav-text">Templates</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Template-kernel-instantiation"><span class="nav-number">1.5.2.</span> <span class="nav-text">Template kernel instantiation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Dimensionality-independent-programming"><span class="nav-number">1.5.3.</span> <span class="nav-text">Dimensionality-independent programming</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tensor-size-reflection"><span class="nav-number">1.5.4.</span> <span class="nav-text">Tensor-size reflection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Compile-time-branching"><span class="nav-number">1.5.5.</span> <span class="nav-text">Compile-time branching</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Forced-loop-unrolling"><span class="nav-number">1.5.6.</span> <span class="nav-text">Forced loop-unrolling</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Variable-aliasing"><span class="nav-number">1.5.7.</span> <span class="nav-text">Variable aliasing</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Differentiable-Programming"><span class="nav-number">1.6.</span> <span class="nav-text">Differentiable Programming</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Gradient-based-optimization"><span class="nav-number">1.6.1.</span> <span class="nav-text">Gradient-based optimization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Application-1-Forces-from-potential-energy-gradients"><span class="nav-number">1.6.2.</span> <span class="nav-text">Application 1: Forces from potential energy gradients</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Application-2-Differentiating-a-whole-physical-process"><span class="nav-number">1.6.3.</span> <span class="nav-text">Application 2: Differentiating a whole physical process</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Visualization"><span class="nav-number">1.7.</span> <span class="nav-text">Visualization</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2、Lagrangian-Simulation-Approaches"><span class="nav-number">2.</span> <span class="nav-text">2、Lagrangian Simulation Approaches</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Mass-Spring-Systems-弹簧质点系统"><span class="nav-number">2.1.</span> <span class="nav-text">Mass-Spring Systems (弹簧质点系统)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Time-integration"><span class="nav-number">2.2.</span> <span class="nav-text">Time integration</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Implementing-a-mass-spring-system-with-symplectic-Euler"><span class="nav-number">2.2.1.</span> <span class="nav-text">Implementing a mass-spring system with symplectic Euler</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Explicit-v-s-implicit-time-integrators"><span class="nav-number">2.2.2.</span> <span class="nav-text">Explicit v.s. implicit time integrators</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Mass-spring-systems"><span class="nav-number">2.2.3.</span> <span class="nav-text">Mass-spring systems</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Solving-linear-systems-with-Jacobi-iterations"><span class="nav-number">2.2.4.</span> <span class="nav-text">Solving linear systems with Jacobi iterations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Unifying-explicit-and-implicit-integrators"><span class="nav-number">2.2.5.</span> <span class="nav-text">Unifying explicit and implicit integrators</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Lagrangian-fluid-simulation-SPH"><span class="nav-number">2.3.</span> <span class="nav-text">Lagrangian fluid simulation: SPH</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Implementing-SPH-using-the-Equation-of-States"><span class="nav-number">2.3.1.</span> <span class="nav-text">Implementing SPH using the Equation of States</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Gradients-in-SPH"><span class="nav-number">2.3.2.</span> <span class="nav-text">Gradients in SPH</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SPH-Simulation-Cycle"><span class="nav-number">2.3.3.</span> <span class="nav-text">SPH Simulation Cycle</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Variants-of-SPH"><span class="nav-number">2.3.4.</span> <span class="nav-text">Variants of SPH</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Courant–Friedrichs–Lewy-CFL-condition"><span class="nav-number">2.3.5.</span> <span class="nav-text">Courant–Friedrichs–Lewy (CFL) condition</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Accelerating-SPH-Neighborhood-search"><span class="nav-number">2.3.6.</span> <span class="nav-text">Accelerating SPH: Neighborhood search</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3、Basics-of-deformation-elasticity-and-finite-elements"><span class="nav-number">3.</span> <span class="nav-text">3、Basics of deformation, elasticity, and finite elements</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Deformation"><span class="nav-number">3.1.</span> <span class="nav-text">Deformation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Elasticity"><span class="nav-number">3.2.</span> <span class="nav-text">Elasticity</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Hyperelasticity"><span class="nav-number">3.2.1.</span> <span class="nav-text">Hyperelasticity</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Stress-tensor"><span class="nav-number">3.2.2.</span> <span class="nav-text">Stress tensor</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Daphne Wang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">12</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Daphne Wang</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
