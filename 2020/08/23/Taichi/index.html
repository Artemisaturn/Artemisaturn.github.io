

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="Wang Jiamin">
  <meta name="keywords" content="">
  <title>Taichi - Hexo</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.4.0/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"artemisaturn.github.io","root":"/","version":"1.8.7","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"onlypost":false},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}}};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.3.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Fluid</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="Taichi">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2020-08-23 23:09" pubdate>
        2020年8月23日 晚上
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      3.8k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      72
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Taichi</h1>
            
            <div class="markdown-body">
              <h1 id="1、The-Taichi-Programming-Language"><a href="#1、The-Taichi-Programming-Language" class="headerlink" title="1、The Taichi Programming Language"></a>1、The Taichi Programming Language</h1><h2 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h2><h3 id="Data-types"><a href="#Data-types" class="headerlink" title="Data types"></a>Data types</h3><p>Taichi is strongly typed. Supported basics types include:</p>
<ul>
<li>Signed integers:  ti.i8/i16/i32/i64</li>
<li>Unsigned integers:  ti.u8/u16/u32/u64</li>
<li>Float-point numbers:  ti.f32/f64</li>
</ul>
<h3 id="Tensors"><a href="#Tensors" class="headerlink" title="Tensors"></a>Tensors</h3><p>Taichi is a data-oriented programming language where tensors are first-class citizens.</p>
<ul>
<li>Tensors are essentially multi-dimensional arrays.（在Taichi种，tensor和matrix是两个完全不同的概念）</li>
<li>An element of a tensor can be either a scalar(var), a vector(ti.Vector), or a matrix(ti.Matrix)</li>
<li>Tensor elements are always accessed via the a[i, j, k] syntax. (No pointers! 编译器不易优化)</li>
<li>Access out-of-bound is undefined behavior.</li>
<li>Tensors can be spatially  sparse.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> taichi <span class="hljs-keyword">as</span> ti<br>ti.init()<br>a = ti.var(dt=ti.f32, shape=(<span class="hljs-number">42</span>, <span class="hljs-number">63</span>)) <span class="hljs-comment"># A tensor of 42x63 scalars</span><br>b = ti.Vector(<span class="hljs-number">3</span>, dt=ti.f32, shape=<span class="hljs-number">4</span>) <span class="hljs-comment"># A tensor of 4x3D vectors</span><br>C = ti.Matrix(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, dt=ti.f32, shape=(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>)) <span class="hljs-comment"># A tensor pf 3x5 2x2 matrices</span><br>loss = ti.var(dt=ti.f32, shape=()) <span class="hljs-comment"># A (0-D) tensor of a single scalar</span><br><br>a[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>] = <span class="hljs-number">1</span><br>print(<span class="hljs-string">&#x27;a[3, 4] = &#x27;</span>, a[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>])<br><span class="hljs-comment"># &quot;a[3, 4] = 1.000000&quot;</span><br><br>b[<span class="hljs-number">2</span>] = [<span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>]<br>print(<span class="hljs-string">&#x27;b[0] =&#x27;</span>, b[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>], b[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>], b[<span class="hljs-number">0</span>][<span class="hljs-number">2</span>])<br><span class="hljs-comment"># print(b[0]) is not yet supported</span><br><br>loss[<span class="hljs-literal">None</span>] = <span class="hljs-number">3</span> <span class="hljs-comment"># 没有下标</span><br>print(loss[<span class="hljs-literal">None</span>]) <span class="hljs-comment"># 3</span><br></code></pre></td></tr></table></figure>
<p>a（标量张量）：有42x63个元素，每个元素是一个标量</p>
<p>b（向量张量）：tensor长度为4，向量有3个元素，4个3D vectors组成的张量</p>
<p>c（矩阵张量）：3x5的tensor，里面每个元素是一个2x2的矩阵</p>
<p>loss：0-D的张量，只有一个标量元素</p>
<h2 id="computation"><a href="#computation" class="headerlink" title="computation"></a>computation</h2><h3 id="Kernels"><a href="#Kernels" class="headerlink" title="Kernels"></a>Kernels</h3><p>Kernels——用来计算的函数。</p>
<ul>
<li>The language used in Taichi kernels and functions is similar to Python.（区别：该语言会被即时编译，Taichi自带一个编译器，把kernel里的语言编译成高性能kernel，能够运行的更快。）</li>
<li>The Taichi kernel lanuage is compiled, statically-typed, lexically-scoped, parallel and differentiable.</li>
<li>Kernels must be decorated with @ti.kernel.</li>
<li>Kernel arguments and return values must be type-hinted.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hello</span>(<span class="hljs-params">i: ti.i32</span>):</span><br>    a = <span class="hljs-number">40</span><br>    print(<span class="hljs-string">&#x27;Hello world!&#x27;</span>, a + i)<br>    <br>hello(<span class="hljs-number">2</span>) <span class="hljs-comment"># Hello world! 42</span><br><br><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">calc</span>() -&gt; ti.i32:</span><br>    s = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        s += i<br>    <span class="hljs-keyword">return</span> s  <span class="hljs-comment"># 45</span><br></code></pre></td></tr></table></figure>
<h3 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h3><p>Taichi Functions 可以被 Taichi Kernels 调用，但是Taichi Function 不能被 python 调用。（<strong>device</strong> functions；<strong>global</strong> kernels）</p>
<p>Taichi functions can be called by Taichi kernels and other Taichi functions. They must be decorated with @ti.func.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@ti.func</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">triple</span>(<span class="hljs-params">x</span>):</span><br>    <span class="hljs-keyword">return</span> x * <span class="hljs-number">3</span><br><br><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">triple_array</span>:</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>        a[i] = triple(a[i])<br></code></pre></td></tr></table></figure>
<p>Taichi Function will be force-inlined. 暂时不支持递归。一个Taichi Function最多只能包含一条return statement。</p>
<h3 id="Matrices-and-linear-algebra"><a href="#Matrices-and-linear-algebra" class="headerlink" title="Matrices and linear algebra"></a>Matrices and linear algebra</h3><ul>
<li>ti.Matrix is for small matrices(e.g. 3x3) only.</li>
<li>ti.Vector is the same as ti.Matrix, except that it has only one column.</li>
</ul>
<p><strong>Note:</strong>  Differentiate element-wise product * and matrix product @</p>
<h4 id="Parallel-for-loops"><a href="#Parallel-for-loops" class="headerlink" title="Parallel for-loops"></a>Parallel for-loops</h4><p>For loops in Taichi have two forms:</p>
<ul>
<li><strong>Range-for loops</strong>, which are no different from Python for loops, except that it will be parallelized when used at the outermost scope. Range-for loops can be nested.</li>
<li><strong>Struct-for loops</strong>, which iterates over (sparse) tensor elements. </li>
</ul>
<p>For loops at the outermost scope in a Taichi kernel is <strong>automatically parallelized</strong>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fill</span>():</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):  <span class="hljs-comment"># Parallelized</span><br>        x[i] += i<br>        <br>        s = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):  <span class="hljs-comment"># Serialized in each parallel thread</span><br>            s += j<br>         <br>        y[i] = s<br>      <br><span class="hljs-meta">@ti,kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fill_3d</span>():</span><br>    <span class="hljs-comment"># Parallelized for all 3&lt;=i&lt;8, 1&lt;=j&lt;6, 0&lt;=k&lt;9</span><br>    <span class="hljs-keyword">for</span> i, j, k <span class="hljs-keyword">in</span> ti.ndrange((<span class="hljs-number">3</span>, <span class="hljs-number">8</span>), (<span class="hljs-number">1</span>, <span class="hljs-number">6</span>), <span class="hljs-number">9</span>):<br>        x[i, j, k] = i + j + k<br></code></pre></td></tr></table></figure>
<p><strong>Note:</strong> It is the loop at the outermost scope that gets parallelized, not the outermost loop.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">foo</span>():</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>): <span class="hljs-comment"># Parallelized</span><br>        ...<br>      <br><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">bar</span>(<span class="hljs-params">k: ti.i32</span>):</span><br>    <span class="hljs-keyword">if</span> k &gt; <span class="hljs-number">42</span>:<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>): <span class="hljs-comment"># Serical</span><br>            ...<br></code></pre></td></tr></table></figure>
<h4 id="Struct-for-loops"><a href="#Struct-for-loops" class="headerlink" title="Struct-for loops"></a>Struct-for loops</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> taichi <span class="hljs-keyword">as</span> ti<br><br>ti.init(arch=ti.gpu)<br><br>n = <span class="hljs-number">320</span><br>pixels = ti.var(dt=ti.f32, shape=(n * <span class="hljs-number">2</span>, n))<br><br><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">paint</span>(<span class="hljs-params">t: ti.f32</span>):</span><br>    <span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> pixels:  <span class="hljs-comment"># Parallelized over all pixels</span><br>        pixels[i, j] = i * <span class="hljs-number">0.001</span> + j * <span class="hljs-number">0.002</span> + t<br>        <br>paint(<span class="hljs-number">0.3</span>)<br></code></pre></td></tr></table></figure>
<h3 id="Atomic-Operations"><a href="#Atomic-Operations" class="headerlink" title="Atomic Operations"></a>Atomic Operations</h3><p>In Taichi, augmented assignments (e.g.  x[i] += 1) are automatically atomic.</p>
<p>When modifying global variables in parallel, make sure you use atomic operations.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sum</span>():</span><br>	<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x:<br>	<span class="hljs-comment"># Approach 1: OK</span><br>	total[<span class="hljs-literal">None</span>] += x[i]  <span class="hljs-comment"># total 0-D tensor</span><br>    <br>	<span class="hljs-comment"># Approach 2: OK</span><br>	ti.atomic_add(total[<span class="hljs-literal">None</span>], x[i])<br>    <br>	<span class="hljs-comment"># Approach 3: Wrong result (the operation is not atomic .)</span><br>	total[<span class="hljs-literal">None</span>] = total[<span class="hljs-literal">None</span>] + x[i]<br></code></pre></td></tr></table></figure>
<h3 id="Taichi-scope-v-s-Python-scope"><a href="#Taichi-scope-v-s-Python-scope" class="headerlink" title="Taichi-scope v.s. Python-scope"></a>Taichi-scope v.s. Python-scope</h3><p><strong>Definition：</strong></p>
<ul>
<li>Taichi-scope: Everything decorated with ti.kernel and ti.func.</li>
<li>Python-scope: Code outside the Taichi-scope.</li>
</ul>
<p><strong>Note：</strong></p>
<ul>
<li>Code in Taichi-scope will be compiled by the Taichi compiler and run on parallel devices.</li>
<li>Code in Python-scope is simply Python code and will be executed by the Python interpreter.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> taichi <span class="hljs-keyword">as</span> ti<br>ti.init()<br><br>a = ti.var(dt=ti.f32, shape=(<span class="hljs-number">42</span>, <span class="hljs-number">63</span>)) <span class="hljs-comment"># A tensor of 42x63 scalars</span><br>b = ti.Vector(<span class="hljs-number">3</span>, dt=ti.f32, shape=<span class="hljs-number">4</span>) <span class="hljs-comment"># A tensor of 4x3D vectors</span><br>C = ti.Matrix(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, dt=ti.f32, shape=(<span class="hljs-number">3</span>,<span class="hljs-number">5</span>)) <span class="hljs-comment"># A tensor of 3x5 2x2 matrices</span><br><br><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">foo</span>():</span><br>    a[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>] = <span class="hljs-number">1</span><br>    print(<span class="hljs-string">&#x27;a[3, 4] =&#x27;</span>, a[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]) <br>    <span class="hljs-comment"># a[3, 4] = 1.000000</span><br>    <br>    b[<span class="hljs-number">2</span>] = [<span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>]<br>    print(<span class="hljs-string">&#x27;b[0] =&#x27;</span>, b[<span class="hljs-number">0</span>], <span class="hljs-string">&#x27;, b[2] =&#x27;</span>, b[<span class="hljs-number">2</span>])<br>    <span class="hljs-comment"># b[0] = [0.000000, 0.000000, 0.000000] , b[2] = [6.000000, 7.000000, 8.000000]</span><br>    <br>    C[<span class="hljs-number">2</span>, <span class="hljs-number">1</span>][<span class="hljs-number">0</span>, <span class="hljs-number">1</span>] = <span class="hljs-number">1</span><br>    print(<span class="hljs-string">&#x27;C[2, 1] =&#x27;</span>, C[<span class="hljs-number">2</span>, <span class="hljs-number">1</span>])<br>    <span class="hljs-comment"># C[2, 1] = [[0.000000, 1.000000], [0.000000, 0.000000]]</span><br>    <br>foo()<br></code></pre></td></tr></table></figure>
<h3 id="Phases-of-a-Taichi-program"><a href="#Phases-of-a-Taichi-program" class="headerlink" title="Phases of a Taichi program"></a>Phases of a Taichi program</h3><ol>
<li>Initialization: ti.init(…)</li>
<li>Tensor allocation: ti.var, ti.Vector, ti.Matrix</li>
<li>Computation (launch kernels, access tensors in Python-scope)</li>
<li>Optional: restart the Taichi system (clear memory, destroy all variables and kernels): ti.reset()</li>
</ol>
<p><strong>Note</strong></p>
<p>For now, after the first kernel launch or tensor access in Python-scope, no more tensor allocation is allowed.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># fractal.py</span><br><span class="hljs-keyword">import</span> taichi <span class="hljs-keyword">as</span> ti<br>ti.init(arch=ti.gpu)<br><br>n = <span class="hljs-number">320</span><br>pixels = ti.var(dt=ti.f32, shape=(n * <span class="hljs-number">2</span>, n))<br><br><span class="hljs-meta">@ti.func</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">complex_sqr</span>(<span class="hljs-params">z</span>):</span><br>    <span class="hljs-keyword">return</span> ti.Vector([z[<span class="hljs-number">0</span>]**<span class="hljs-number">2</span> - z[<span class="hljs-number">1</span>]**<span class="hljs-number">2</span>, z[<span class="hljs-number">1</span>]*z[<span class="hljs-number">0</span>]*<span class="hljs-number">2</span>])<br><br><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">paint</span>(<span class="hljs-params">t: ti.f32</span>):</span><br>    <span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> pixels: <span class="hljs-comment"># Parallelized over all pixels</span><br>        c = ti.Vector([-<span class="hljs-number">0.8</span>, ti.cos(t)*<span class="hljs-number">0.2</span>])<br>        z = ti.Vector([i/n-<span class="hljs-number">1</span>, j/n-<span class="hljs-number">0.5</span>]) * <span class="hljs-number">2</span><br>        iterations = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">while</span> z.norm() &lt; <span class="hljs-number">20</span> <span class="hljs-keyword">and</span> iterations &lt;<span class="hljs-number">50</span>:<br>            z = complex_sqr(z) + c<br>            iterations += <span class="hljs-number">1</span><br>        pixels[i, j] = <span class="hljs-number">1</span> - iterations * <span class="hljs-number">0.02</span><br>        <br>gui = ti.GUI(<span class="hljs-string">&quot;Julia Set&quot;</span>, res=(n*<span class="hljs-number">2</span>, n))<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1000000</span>):<br>    paint(i * <span class="hljs-number">0.03</span>)<br>    gui.set_image(pixels)<br>    gui.show()<br></code></pre></td></tr></table></figure>
<h2 id="Debugging"><a href="#Debugging" class="headerlink" title="Debugging"></a>Debugging</h2><h3 id="Debug-mode"><a href="#Debug-mode" class="headerlink" title="Debug mode"></a>Debug mode</h3><p> ti.init(debug=True, arch=ti.cpu) initializes Taichi in debug mode, which enables bound checkers (CPU only).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> taichi <span class="hljs-keyword">as</span> ti<br>ti.init(debug=<span class="hljs-literal">True</span>, arch=ti.cpu)<br><br>a = ti.var(ti.i32, shape=(<span class="hljs-number">10</span>))<br>b = ti.var(ti.i32, shape=(<span class="hljs-number">10</span>))<br><br><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">shift</span>():</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        a[i] = b[i+<span class="hljs-number">1</span>] <span class="hljs-comment"># Runtime error in debug mode</span><br>        <br>shift()<br></code></pre></td></tr></table></figure>
<h2 id="Objective-data-oriented-programming"><a href="#Objective-data-oriented-programming" class="headerlink" title="Objective data-oriented programming"></a>Objective data-oriented programming</h2><p>Taichi is a data-oriented programming (DOP) language, but simple DOP makes modularization hard. To improve code reusability, Taichi borrows some concepts from object-oriented programming (OOP).</p>
<p>The hybrid scheme is called objective data-oriented programming (ODOP).</p>
<p>Three important decorators</p>
<ul>
<li>Use @ti.data_oriented to decorate your class.</li>
<li>Use @ti.kernel to decorate class members functions that are Taichi kernels.</li>
<li>Use @ti.func to decorate class members functions that are Taichi functions.</li>
</ul>
<p>Demo:  ti example odop_solar  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> taichi <span class="hljs-keyword">as</span> ti<br><span class="hljs-keyword">import</span> math<br>ti.init()<br><br><span class="hljs-meta">@ti.data_oriented</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SolarSystem</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, n, dt</span>):</span><br>        <span class="hljs-comment"># initializer of the solar system simulator</span><br>        self.n = n<br>        self.dt = dt<br>        self.x = ti.Vector.field(<span class="hljs-number">2</span>, dtype=<span class="hljs-built_in">float</span>, shape=n)<br>        self.v = ti.Vector.field(<span class="hljs-number">2</span>, dtype=<span class="hljs-built_in">float</span>, shape=n)<br>        self.center = ti.Vector.field(<span class="hljs-number">2</span>, dtype=<span class="hljs-built_in">float</span>, shape=())<br><br><span class="hljs-meta">    @staticmethod</span><br><span class="hljs-meta">    @ti.func</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">random_vector_in</span>(<span class="hljs-params">rmax</span>):</span><br>        <span class="hljs-comment"># create a random vector</span><br>        a = ti.random() * math.tau<br>        r = ti.random() * rmax<br>        <span class="hljs-keyword">return</span> r * ti.Vector([ti.cos(a), ti.sin(a)])<br><br><span class="hljs-meta">    @ti.kernel</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">initialize</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-comment"># initialization or reset</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.n):<br>            offset = self.random_vector_in(<span class="hljs-number">0.5</span>)<br>            self.x[i] = self.center[<span class="hljs-literal">None</span>] + offset  <span class="hljs-comment"># Offset from center</span><br>            self.v[i] = [-offset.y, offset.x]  <span class="hljs-comment"># Perpendicular to offset</span><br>            self.v[i] += self.random_vector_in(<span class="hljs-number">0.02</span>)  <span class="hljs-comment"># Shaking</span><br>            self.v[i] *= <span class="hljs-number">1</span> / offset.norm()**<span class="hljs-number">1.5</span>  <span class="hljs-comment"># Kepler&#x27;s 3rd law</span><br><br><span class="hljs-meta">    @ti.func</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gravity</span>(<span class="hljs-params">self, pos</span>):</span><br>        <span class="hljs-comment"># compute gravitational acceleration at pos</span><br>        offset = -(pos - self.center[<span class="hljs-literal">None</span>])<br>        <span class="hljs-keyword">return</span> offset / offset.norm()**<span class="hljs-number">3</span><br><br><span class="hljs-meta">    @ti.kernel</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">integrate</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-comment"># semi-implicit time integration</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.n):<br>            self.v[i] += self.dt * self.gravity(self.x[i])<br>            self.x[i] += self.dt * self.v[i]<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">render</span>(<span class="hljs-params">self, gui</span>):</span><br>        <span class="hljs-comment"># render the simulation scene on the GUI</span><br>        gui.circle([<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>], radius=<span class="hljs-number">10</span>, color=<span class="hljs-number">0xffaa88</span>)<br>        gui.circles(solar.x.to_numpy(), radius=<span class="hljs-number">3</span>, color=<span class="hljs-number">0xffffff</span>)<br><br><br>solar = SolarSystem(<span class="hljs-number">8</span>, <span class="hljs-number">0.0001</span>)<br>solar.center[<span class="hljs-literal">None</span>] = [<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>]<br>solar.initialize()<br><br>gui = ti.GUI(<span class="hljs-string">&quot;Solar System&quot;</span>, background_color=<span class="hljs-number">0x0071a</span>)<br><br><span class="hljs-keyword">while</span> gui.running:<br>    <span class="hljs-comment"># GUI event processing</span><br>    <span class="hljs-keyword">if</span> gui.get_event(gui.PRESS):<br>        <span class="hljs-keyword">if</span> gui.event.key == gui.SPACE:<br>            solar.initialize()<br>        <span class="hljs-keyword">elif</span> gui.event.key == gui.ESCAPE:<br>            gui.running = <span class="hljs-literal">False</span><br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        solar.integrate()<br><br>    solar.render(gui)<br>    gui.show()<br></code></pre></td></tr></table></figure>
<h2 id="Metaprogramming"><a href="#Metaprogramming" class="headerlink" title="Metaprogramming"></a>Metaprogramming</h2><p>Taichi provides metaprogramming tools. Metaprogramming can :</p>
<ul>
<li>Allow users to pass almost anything (including Taichi tensors) to Taichi kernels</li>
<li>Improve run-time performance by moving run-time costs to compile time</li>
<li>Achieve dimensionality independence (e.g. write 2D and 3D simulation code simultaneously.)</li>
<li>Simplify the development of Taichi standard library</li>
</ul>
<p>Taichi kernels are <strong>lazily instantiated</strong> and a lot of computation can happen at compile time. Every kernel in Taichi is a template kernel, even if it has no template arguments.</p>
<h3 id="Templates"><a href="#Templates" class="headerlink" title="Templates"></a>Templates</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">copy</span>(<span class="hljs-params">x: ti.template (<span class="hljs-params"></span>), y: ti.template (<span class="hljs-params"></span>), c: ti.f32</span>):</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x:   <br>        y[i] = x[i] + c<br></code></pre></td></tr></table></figure>
<p>如果不用template很难把tensor当argument传给kernel</p>
<p><strong>Template instantiation</strong></p>
<p>Kernel templates will be instantiated on the first call, and cached for later calls with the same template signature.</p>
<p><strong>Template argument takes (almost) everything</strong></p>
<p>Feel free to pass tensors, classes, functions, and numerical values to ti.template() arguments.</p>
<h3 id="Template-kernel-instantiation"><a href="#Template-kernel-instantiation" class="headerlink" title="Template kernel instantiation"></a>Template kernel instantiation</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> taichi <span class="hljs-keyword">as</span> ti<br>ti.init()<br><br><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hello</span>(<span class="hljs-params">i: ti.template (<span class="hljs-params"></span>)</span>):</span><br>    print(i)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span> (<span class="hljs-number">100</span>):<br>    hello(i) <span class="hljs-comment"># 100 different kernels will be created</span><br>    <br><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">world</span>(<span class="hljs-params">i: ti.i32</span>):</span><br>    print(i)<br>    <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span> (<span class="hljs-number">100</span>):<br>    world(i) <span class="hljs-comment"># The only instance will be reused</span><br></code></pre></td></tr></table></figure>
<h3 id="Dimensionality-independent-programming"><a href="#Dimensionality-independent-programming" class="headerlink" title="Dimensionality-independent programming"></a>Dimensionality-independent programming</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">copy</span>(<span class="hljs-params">x: ti.template(<span class="hljs-params"></span>), y: ti.template(<span class="hljs-params"></span>)</span>):</span><br>    <span class="hljs-keyword">for</span> I <span class="hljs-keyword">in</span> ti.grouped(y):  <span class="hljs-comment"># 将y的全部index打包,I--&gt;n维向量</span><br>        x[I] = y[I]<br>        <br><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">array_op</span>(<span class="hljs-params">x: ti.template(<span class="hljs-params"></span>), y: ti.template(<span class="hljs-params"></span>)</span>):</span><br>    <span class="hljs-keyword">for</span> I <span class="hljs-keyword">in</span> ti.grouped(x):<br>        <span class="hljs-comment"># I is a vector of size x.dim() and data type i32</span><br>        y[I] = I[<span class="hljs-number">0</span>] + I[<span class="hljs-number">1</span>]<br>    <span class="hljs-comment"># If tensor x is 2D, the above is equivalent to</span><br>    <span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> x:<br>        y[i, j] = i + j<br></code></pre></td></tr></table></figure>
<h3 id="Tensor-size-reflection"><a href="#Tensor-size-reflection" class="headerlink" title="Tensor-size reflection"></a>Tensor-size reflection</h3><p>Fetch tensor dimensionality info as compile-time constants:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> taichi <span class="hljs-keyword">as</span> ti<br><br>tensor = ti.var(ti.f32, shape=(<span class="hljs-number">4</span>, <span class="hljs-number">8</span>, <span class="hljs-number">16</span>, <span class="hljs-number">32</span>, <span class="hljs-number">64</span>))<br><br><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">print_tensor_size</span>(<span class="hljs-params">x: ti.template(<span class="hljs-params"></span>)</span>):</span><br>    print(<span class="hljs-built_in">len</span>(x.shape))  <span class="hljs-comment"># x.dim() &amp; x.shape() is deprecated</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> ti.static(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(x.shape))):<br>        print(x.shape[i])<br><br>print_tensor_size(tensor)<br></code></pre></td></tr></table></figure>
<h3 id="Compile-time-branching"><a href="#Compile-time-branching" class="headerlink" title="Compile-time branching"></a>Compile-time branching</h3><p>Using compile-time evaluation will allow certain computations to happen when kernels are being instantiated. This saves the overhead of those computations at runtime. (C++17 equivalence: if constexpr.)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">enable_projection = <span class="hljs-literal">True</span><br><br><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">static</span>():</span><br>    <span class="hljs-keyword">if</span> ti.static(enable_projection): <span class="hljs-comment"># No runtime overhead</span><br>        x[<span class="hljs-number">0</span>] = <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure>
<h3 id="Forced-loop-unrolling"><a href="#Forced-loop-unrolling" class="headerlink" title="Forced loop-unrolling"></a>Forced loop-unrolling</h3><p>Use ti.static(range(…)) to unroll the loops at compile time:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> taichi <span class="hljs-keyword">as</span> ti<br><br>ti.init()<br>x = ti.Vector(<span class="hljs-number">3</span>, dt=ti.i32, shape =<span class="hljs-number">16</span>)<br><br><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fill</span>():</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x:<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> ti.static(<span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>)):<br>            x[i][j] = j<br>        print(x[i])<br><br>fill()<br></code></pre></td></tr></table></figure>
<p>When to use range-for loops?</p>
<ul>
<li>For performance.  （loop-unrolling后可以减少loop本身的overhead）</li>
<li>To loop over vector/matrix elements. Indices into Taichi matrices must be compile-time constants. Indices into Taichi tensors can be run-time variables. For example, if x is a 1-D tensor of 3D vectors, accessed as x [tensor_index] [matrix_index]. The first index can be a variable, yet the second must be a constant.</li>
</ul>
<h3 id="Variable-aliasing"><a href="#Variable-aliasing" class="headerlink" title="Variable aliasing"></a>Variable aliasing</h3><p>Creating handy aliases for global variables and functions with cumbersome names can sometimes improve readability:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">my_kernel</span> ():</span><br>    <span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> tensor_a:<br>        tensor_b[i, j] = some_function(tensor_a[i, j])<br>        <br><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">my_kernel</span> ():</span><br>    a, b, fun = ti.static(tensor_a , tensor_b , some_function)<br>    <span class="hljs-keyword">for</span> i,j <span class="hljs-keyword">in</span> a:<br>        b[i,j] = fun(a[i,j])<br></code></pre></td></tr></table></figure>
<h2 id="Differentiable-Programming"><a href="#Differentiable-Programming" class="headerlink" title="Differentiable Programming"></a>Differentiable Programming</h2><p>Forward programs evaluate $f(x)$, differentiable programs evaluate $\frac{∂f(x)}{∂x}$</p>
<p>Taichi supports <strong>reverse-mode automatic differentiation (AutoDiff)</strong> that back-propagates gradients w.r.t. a scalar (loss) function f(x).</p>
<p>Two ways to compute gradients:</p>
<ol>
<li>Use Taichi’s tape (ti.Tape(loss)) for both forward and gradient evaluation.</li>
<li>Explicitly use gradient kernels for gradient evaluation with more controls.</li>
</ol>
<h3 id="Gradient-based-optimization"><a href="#Gradient-based-optimization" class="headerlink" title="Gradient-based optimization"></a>Gradient-based optimization</h3><p>$$<br>min_x \quad L(x) = \frac{1}{2}\sum_{i=0}^{n-1}(x_i - y_i)^2<br>$$</p>
<ol>
<li><p>Allocating tensors with gradients：x = ti.var(dt=ti.f32, shape=n, needs_grad=True)</p>
</li>
<li><p>Defining loss function kernel(s)：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reduce</span> ():</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>        L[<span class="hljs-literal">None</span>] += <span class="hljs-number">0.5</span> * (x[i] - y[i])**<span class="hljs-number">2</span><br></code></pre></td></tr></table></figure></li>
<li><p>Compute loss with ti.Tape(loss=L)：reduce()</p>
</li>
<li><p>Gradient descent：for i in x: x[i] -= x.grad[i] * 0.1</p>
</li>
</ol>
<h3 id="Application-1-Forces-from-potential-energy-gradients"><a href="#Application-1-Forces-from-potential-energy-gradients" class="headerlink" title="Application 1: Forces from potential energy gradients"></a>Application 1: Forces from potential energy gradients</h3><p>From the definition of potential energy: (potential energy关于位置的导数–&gt;顶点的受力)<br>$$<br>f_i = -\frac{∂U(x)}{∂x_i}<br>$$<br>Manually deriving gradients is hard. Let’s use AutoDiff:</p>
<ol>
<li>Allocate a 0−D tensor to store the potential energy: potential = ti.var(ti.f32, shape=()).</li>
<li>Define forward kernels that computes potential energy from x[i].</li>
<li>In a ti.Tape(loss=potential), call the forward kernels.</li>
<li>Force on each particle is -x.grad[i].</li>
</ol>
<h3 id="Application-2-Differentiating-a-whole-physical-process"><a href="#Application-2-Differentiating-a-whole-physical-process" class="headerlink" title="Application 2: Differentiating a whole physical process"></a>Application 2: Differentiating a whole physical process</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> ti.Tape(loss=loss):<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(steps - <span class="hljs-number">1</span>):<br>        simulate(i)<br></code></pre></td></tr></table></figure>
<p><strong>Computational history</strong></p>
<p>Always keep the whole computational history of time steps for end-to-end differentiation. I.e., instead of only allocating<br>ti.Vector(3, dt=ti.f32, shape=(num_particles)) that stores the latest particles, allocate for the whole simulation process<br>ti.Vector(3, dt=ti.f32, shape=(num_timesteps, num_particles)). (Use checkpointing to reduce memory consumption.)</p>
<h2 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h2><p><strong>Visualizing 2D results</strong></p>
<p>Simply make use of Taichi’s GUI system. Useful functions:</p>
<ul>
<li>gui = ti.GUI(“Taichi MLS-MPM-128”, res=512, background_color=0x112F41)</li>
<li>gui.circle/gui.circles(x.to_numpy(), radius=1.5, color=colors.to_numpy())</li>
<li>gui.line/triangle/set_image/show/…</li>
</ul>
<p><strong>Visualizing 3D results</strong></p>
<p>Exporting 3D particles and meshes using ti.PLYWriter</p>
<p>Use Houdini/Blender to view (and render) your 3D results.</p>
<hr>
<p>ti example: 查看example demo 4</p>
<p>python -m taichi example mpm128 (demo_name)</p>
<h1 id="2、Lagrangian-Simulation-Approaches"><a href="#2、Lagrangian-Simulation-Approaches" class="headerlink" title="2、Lagrangian Simulation Approaches"></a>2、Lagrangian Simulation Approaches</h1><h2 id="Mass-Spring-Systems-弹簧质点系统"><a href="#Mass-Spring-Systems-弹簧质点系统" class="headerlink" title="Mass-Spring Systems (弹簧质点系统)"></a>Mass-Spring Systems (弹簧质点系统)</h2><img src="https://hexo-1257922593.cos.ap-beijing.myqcloud.com/taichi/mass_spring.png" srcset="/img/loading.gif" alt="mass_spring" style="zoom:50%;" />

<p>k: spring stiffness; l<sub>ij</sub>: spring rest length between particle i and particle j;</p>
<p>m<sub>i</sub>: the mass of particle i. (<strong>x<sub>i</sub></strong> − <strong>x<sub>j</sub></strong>): direction vector from particle j to particle i;</p>
<h2 id="Time-integration"><a href="#Time-integration" class="headerlink" title="Time integration"></a>Time integration</h2><p><strong>1、Forward Euler</strong> (explicit)：</p>
<p>​        前向欧拉法：根据现有的状态推测以后的状态：</p>
<p>$$<br>v_{t+1} = v_t + \Delta t\frac{f_t}{m}<br>$$</p>
<p>$$<br>x_{t+1} = x_t + \Delta tv_t<br>$$</p>
<p><strong>2、Semi-implicit Euler</strong> (aka. symplectic Euler, explicit)：<br>$$<br>v_{t+1} = v_t + \Delta t\frac{f_t}{m}<br>$$</p>
<p>$$<br>x_{t+1} = x_t + \Delta tv_{t+1}<br>$$</p>
<p><strong>3、Backward Euler</strong> (often with Newton’s method, implicit)：</p>
<h3 id="Implementing-a-mass-spring-system-with-symplectic-Euler"><a href="#Implementing-a-mass-spring-system-with-symplectic-Euler" class="headerlink" title="Implementing a mass-spring system with symplectic Euler"></a>Implementing a mass-spring system with symplectic Euler</h3><ol>
<li><p>Compute new velocity using<br>$$<br>v_{t+1} = v_t + \Delta t\frac{f_t}{m}<br>$$</p>
</li>
<li><p>Collision with ground</p>
</li>
<li><p>Compute new position using<br>$$<br>x_{t+1} = x_t + \Delta tv_{t+1}<br>$$</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># mass_spring.py</span><br><span class="hljs-meta">@ti.kernel</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">substep</span>():</span><br>    n = num_particles[<span class="hljs-literal">None</span>]<br>    <br>    <span class="hljs-comment"># Compute force and new velocity</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>        v[i] *= ti.exp(-dt * damping[<span class="hljs-literal">None</span>]) <span class="hljs-comment"># damping</span><br>        total_force = ti.Vector(gravity) * particle_mass<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            <span class="hljs-keyword">if</span> rest_length[i, j] != <span class="hljs-number">0</span>:<br>                x_ij = x[i] - x[j]<br>                total_force += -spring_stiffness[<span class="hljs-literal">None</span>] * (x_ij.norm() - rest_length[i, j]) * x_ij.normalized()<br>        v[i] += dt * total_force / particle_mass<br>        <br>    <span class="hljs-comment"># Collide with ground</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>        <span class="hljs-keyword">if</span> x[i].y &lt; bottom_y:<br>            x[i].y = bottom_y<br>            v[i].y = <span class="hljs-number">0</span><br>            <br>    <span class="hljs-comment"># Compute new position</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>        x[i] += v[i] * dt<br></code></pre></td></tr></table></figure>
<h3 id="Explicit-v-s-implicit-time-integrators"><a href="#Explicit-v-s-implicit-time-integrators" class="headerlink" title="Explicit v.s. implicit time integrators"></a>Explicit v.s. implicit time integrators</h3><p>Explicit (forward Euler, symplectic Euler, RK, …)：</p>
<ul>
<li><p>Future depends only on past</p>
</li>
<li><p>Easy to implement</p>
</li>
<li><p>Easy to explode: （从材料的刚度考虑时间步长的限制）<br>$$<br>\Delta t \leq c\sqrt{\frac{m}{k}} \quad\quad(c-1)<br>$$</p>
</li>
<li><p>Bad for stiff materials</p>
</li>
</ul>
<p>Implicit (backward Euler, middle-point, …):</p>
<ul>
<li>Future depends on both future and past</li>
<li>Chicken-egg problem: need to solve a system of (linear) equations</li>
<li>In general harder to implement</li>
<li>Each step is more expensive but time steps are larger</li>
<li>Numerical damping and locking</li>
</ul>
<h3 id="Mass-spring-systems"><a href="#Mass-spring-systems" class="headerlink" title="Mass-spring systems"></a>Mass-spring systems</h3><p>Implicit time integration:<br>$$<br>x_{t+1} = x_t + \Delta tv_{t+1} \quad\quad (1)<br>$$</p>
<p>$$<br>v_{t+1} = v_t + \Delta tM^{-1}f(x_{t+1}) \quad\quad (2)<br>$$</p>
<p>Eliminate x<sub>t+1</sub>:<br>$$<br>v_{t+1} = v_t + \Delta tM^{-1}f(x_t + \Delta tv_{t+1}) \quad\quad (3)<br>$$<br>Linearize (one step of Newton’s method):<br>$$<br>v_{t+1} = v_t + \Delta tM^{-1}[f(x_t) + \frac{∂f}{∂x}(x_t)\Delta tv_{t+1}] \quad\quad (4)<br>$$<br>Clean up:<br>$$<br>[I - \Delta t^2M^{-1}\frac{∂f}{∂x}(x_t)] v_{t+1} = v_t + \Delta tM^{-1}f(x_t) \quad\quad (5)<br>$$<br>How to solve it?</p>
<ul>
<li>Jacobi/Gauss-Seidel iterations (easy to implement!)</li>
<li>Conjugate gradients (later in this course)</li>
</ul>
<p>$$<br>A = [I - \Delta t^2M^{-1}\frac{∂f}{∂x}(x_t)]<br>$$</p>
<p>$$<br>b = v_t + \Delta tM^{-1}f(x_t)<br>$$</p>
<p>$$<br>Av_{t+1} = b<br>$$</p>
<h3 id="Unifying-explicit-and-implicit-integrators"><a href="#Unifying-explicit-and-implicit-integrators" class="headerlink" title="Unifying explicit and implicit integrators"></a>Unifying explicit and implicit integrators</h3><p>$$<br>[I - \beta\Delta t^2M^{-1}\frac{∂f}{∂x}(x_t)] v_{t+1} = v_t + \Delta tM^{-1}f(x_t)<br>$$</p>
<ol>
<li>β = 0: forward/semi-implicit Euler (explicit)</li>
<li>β = 1/2: middle-point (implicit)</li>
<li>β = 1: backward Euler (implicit)</li>
</ol>
<h2 id="Lagrangian-fluid-simulation-SPH"><a href="#Lagrangian-fluid-simulation-SPH" class="headerlink" title="Lagrangian fluid simulation: SPH"></a>Lagrangian fluid simulation: SPH</h2><p><strong>High-level idea:</strong> use particles carrying samples of physical quantities, and a kernel function W, to approximate continuous fields: (<em>A</em> can be almost any spatially varying physical attributes: density, pressure, etc. Derivatives: different story)<br>$$<br>A(x) = \sum_i{A_i}\frac{m_i}{ρ_i}W(||x-x_j||_2, h)<br>$$</p>
<ol>
<li>Originally proposed for astrophysical problems</li>
<li>No meshes. Very suitable for free-surface flows!</li>
<li>Easy to understand intuitively: just imagine each particle is a small parcel of water (although strictly not the case!)</li>
</ol>
<h3 id="Implementing-SPH-using-the-Equation-of-States"><a href="#Implementing-SPH-using-the-Equation-of-States" class="headerlink" title="Implementing SPH using the Equation of States"></a>Implementing SPH using the Equation of States</h3><p>Also known as Weakly Compressible SPH (WCSPH).</p>
<p>Momentum equation: ( ρ: density;  B: bulk modulus;  γ : constant, usually ∼ 7 )<br>$$<br>\frac{Dv}{Dt} = -\frac{1}{ρ}\nabla p + g, \quad\quad p = B((\frac{ρ}{ρ_0})^\gamma - 1)<br>$$</p>
<p>$$<br>A(x) = \sum_i{A_i}\frac{m_i}{ρ_i}W(||x-x_j||_2,h)<br>$$</p>
<p>$$<br>ρ_i = \sum_j{m_j}W(||x_i-x_j||_2,h)<br>$$</p>
<p>Extras: surface tension, viscosity</p>
<p>Note: the WCSPH paper should have used material derivatives.</p>
<h3 id="Gradients-in-SPH"><a href="#Gradients-in-SPH" class="headerlink" title="Gradients in SPH"></a>Gradients in SPH</h3><p>$$<br>\nabla A_i = ρ<em>i \sum{m_j}(\frac{A_i}{ρ_i^2} + \frac{A_j}{ρ_j^2}) \nabla</em>{x_i}W(||x_i-x_j||_2,h)<br>$$</p>
<p>Not really accurate.</p>
<p>But at least symmetric and momentum conserving!</p>
<h3 id="SPH-Simulation-Cycle"><a href="#SPH-Simulation-Cycle" class="headerlink" title="SPH Simulation Cycle"></a>SPH Simulation Cycle</h3><p>$$<br>\frac{Dv}{Dt} = -\frac{1}{ρ}\nabla p + g, \quad\quad p = B((\frac{ρ}{ρ_0})^\gamma - 1)<br>$$</p>
<ol>
<li>For each particle i, compute $ρ_i = \sum{m_j}W(||x_i-x_j||_2,h)$</li>
<li>For each particle i, compute $\nabla p_i$ using the gradient operator</li>
<li>Symplectic Euler step (again…):</li>
</ol>
<p>$$<br>v_{t+1} = v_t + \Delta t\frac{D_v}{D_t}<br>$$</p>
<p>$$<br>x_{t+1} = x_t + \Delta tv_{t+1}<br>$$</p>
<h3 id="Variants-of-SPH"><a href="#Variants-of-SPH" class="headerlink" title="Variants of SPH"></a>Variants of SPH</h3><p>Predictive-Corrective Incompressible SPH (PCI-SPH)：隐式的时间积分（不完全隐式），采用预测矫正的格式，每次先预测一下粒子的位置/速度，然后根据预测做出矫正，得到一个散度比较小的速度场–&gt;更加接近不可压缩</p>
<p>Position-based fluids (PBF) Demo: ti example pbf2d</p>
<p>Divergence-free SPH (DFSPH)</p>
<h3 id="Courant–Friedrichs–Lewy-CFL-condition"><a href="#Courant–Friedrichs–Lewy-CFL-condition" class="headerlink" title="Courant–Friedrichs–Lewy (CFL) condition"></a>Courant–Friedrichs–Lewy (CFL) condition</h3><p>显示时间积分：从粒子运动的速度考虑时间步长的限制：<br>$$<br>C = \frac{u \Delta t}{\Delta x} \leq C_{max} - 1<br>$$</p>
<ul>
<li>C:  CFL number (Courant number, or simple the CFL)</li>
<li>$\Delta t$:  time step</li>
<li>$\Delta x$:  length interval (e.g. particle radius and grid size)</li>
<li>u: maximum (velocity)     $u\Delta t$  –&gt; 一个时间步之内粒子移动的最大距离</li>
</ul>
<p>Application: estimating allowed time step in (explicit) time integrations. Typical C<sub>max</sub> in graphics:</p>
<ul>
<li>SPH: ∼ 0.4</li>
<li>MPM: 0.3 ∼ 1</li>
<li>FLIP fluid (smoke): 1 ∼ 5+</li>
</ul>
<h3 id="Accelerating-SPH-Neighborhood-search"><a href="#Accelerating-SPH-Neighborhood-search" class="headerlink" title="Accelerating SPH: Neighborhood search"></a>Accelerating SPH: Neighborhood search</h3><p>So far, per substep complexity of SPH is $O(n^2)$ . This is too costly to be practical. In practice, people build spatial data structure such as voxel grids to accelerate neighborhood search. This reduces time complexity to O(n).</p>
<h1 id="3、Basics-of-deformation-elasticity-and-finite-elements"><a href="#3、Basics-of-deformation-elasticity-and-finite-elements" class="headerlink" title="3、Basics of deformation, elasticity, and finite elements"></a>3、Basics of deformation, elasticity, and finite elements</h1><h2 id="Deformation"><a href="#Deformation" class="headerlink" title="Deformation"></a>Deformation</h2><p>Deformation map ϕ : a (vector to vector) function that relates rest material position and deformed material position.  (将静止位置映射到形变位置，如果在3D中，即是从三维向量到三维向量的一个向量函数)<br>$$<br>x_{deformed} = \phi (x_{rest})<br>$$<br>Deformation gradient F：（对静止位置求导数）<br>$$<br>F:=\frac{∂x_{deformed}}{∂x_{rest}}<br>$$<br>Deformation gradients are translational invariant:<br>$$<br>\phi_1 = \phi(x_{rest}) \quad and \quad \phi_2 = \phi(x_{rest}) + c<br>$$<br>​        have the same deformation gradients</p>
<p>Deform/rest volume ratio $J = det(F)$   （$J$ ：形变以后的体积/静止的体积 = F的行列式）</p>
<h2 id="Elasticity"><a href="#Elasticity" class="headerlink" title="Elasticity"></a>Elasticity</h2><h3 id="Hyperelasticity"><a href="#Hyperelasticity" class="headerlink" title="Hyperelasticity"></a>Hyperelasticity</h3><p>Hyperelastic materials: materials whose stress–strain relationship is defined by a strain energy density function：<br>$$<br>\psi = \psi(F)<br>$$<br>Intuitive understanding: $\psi$ is a potential function that penalizes deformation.</p>
<p>“Stress”：the material’s internal elastic forces. （用来恢复原来体积形状的内力）</p>
<p>“Strain”：just replace it with deformation gradients F for now.</p>
<p><strong>Be careful</strong></p>
<p>We use ψ as the strain energy density function and ϕ as the deformation map. They are completely different.</p>
<h3 id="Stress-tensor"><a href="#Stress-tensor" class="headerlink" title="Stress tensor"></a>Stress tensor</h3>
            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/language/">language</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/taichi/">taichi</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2020/09/14/Linear-Algebra/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Linear Algebra</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2020/08/23/Weakly-compressible-SPH-for-free-surface-flows/">
                        <span class="hidden-mobile">Weakly compressible SPH for free surface flows</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>

<!-- SCRIPTS -->

  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.0/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.0/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js" ></script>






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    (function () {
      var path = "/local-search.xml";
      var inputArea = document.querySelector("#local-search-input");
      inputArea.onclick = function () {
        searchFunc(path, 'local-search-input', 'local-search-result');
        this.onclick = null
      }
    })()
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-svg.js" ></script>

  











<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>



</body>
</html>
